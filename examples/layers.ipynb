{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nestedtensor import torch\n",
    "def print_eval(s):\n",
    "    print((\"\\033[1;31m$ \" + s + \":\\033[0m\").ljust(30) + \"\\n{}\\n\".format(str(eval(s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom nn.functionals\n",
    "\n",
    "By default all nn.functionals are implemented as a tensorwise function. However, in some cases we want to support custom semantics that come about by slight modifications to the lifted function. Take nn.functional.conv2d as an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt.size():\u001b[0m       \n",
      "(3, 3, None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt = torch.nested_tensor([\n",
    "    torch.rand(3, 10, 30),\n",
    "    torch.rand(3, 20, 40),\n",
    "    torch.rand(3, 30, 50)\n",
    "])\n",
    "nt1 = torch.nested_tensor([\n",
    "    torch.rand(1, 3, 10, 30),\n",
    "    torch.rand(1, 3, 20, 40),\n",
    "    torch.rand(1, 3, 30, 50)\n",
    "])\n",
    "weight = torch.rand(64, 3, 7, 7)\n",
    "print_eval(\"nt.size()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default this function fails, because the components do not have a batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ str(e):\u001b[0m          \n",
      "Expected 4-dimensional input for 4-dimensional weight 64 3 7 7, but got 3-dimensional input of size [3, 10, 30] instead\n",
      "\n",
      "\u001b[1;31m$ torch.tensorwise()(torch.nn.functional.conv2d)(nt1, weight).size():\u001b[0m\n",
      "(3, 1, 64, None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print_eval(\"torch.tensorwise()(torch.nn.functional.conv2d)(nt, weight)\")\n",
    "except RuntimeError as e:\n",
    "    print_eval(\"str(e)\")\n",
    "    \n",
    "print_eval(\"torch.tensorwise()(torch.nn.functional.conv2d)(nt1, weight).size()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, NestedTensors implement a version of conv2d that doesn't require a batch dimension for ease of use and for efficiency (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ torch.nn.functional.conv2d(nt, weight).size():\u001b[0m\n",
      "(3, 64, None, None)\n",
      "\n",
      "(3, 1, None)\n"
     ]
    }
   ],
   "source": [
    "print_eval(\"torch.nn.functional.conv2d(nt, weight).size()\")\n",
    "# print_eval(\"torch.nn.functional.conv2d(nt1, weight).size()\")\n",
    "print(nt1.flatten(2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a similar story for nn.functional.embedding_bag. The lifted version only works on elements of batch size 1, unless given an offset, which is an unnecessary annoyance. We extend the lifted embedding_bag to support inputs of dimension 1, if offset is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt2 = (torch.nested_tensor([\n",
    "    torch.rand(1, 30),\n",
    "    torch.rand(1, 40),\n",
    "    torch.rand(1, 50)\n",
    "]) * 10).to(torch.int64)\n",
    "nt3 = (torch.nested_tensor([\n",
    "    torch.rand(30),\n",
    "    torch.rand(40),\n",
    "    torch.rand(50)\n",
    "]) * 10).to(torch.int64)\n",
    "nt4 = (torch.nested_tensor([\n",
    "    [\n",
    "        torch.rand(1, 30),\n",
    "    ],\n",
    "    [\n",
    "        torch.rand(1, 40),\n",
    "        torch.rand(1, 50)\n",
    "    ]\n",
    "]) * 10).to(torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ torch.nn.functional.embedding_bag(nt2, weight).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([1, 256]),\n",
      "\ttorch.Size([1, 256]),\n",
      "\ttorch.Size([1, 256])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.functional.embedding_bag(nt3, weight).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([256]),\n",
      "\ttorch.Size([256]),\n",
      "\ttorch.Size([256])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.functional.embedding_bag(nt4, weight).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\t(\n",
      "\t\ttorch.Size([1, 256])\n",
      "\t),\n",
      "\t(\n",
      "\t\ttorch.Size([1, 256]),\n",
      "\t\ttorch.Size([1, 256])\n",
      "\t)\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.EmbeddingBag(100, 256)(nt2).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([1, 256]),\n",
      "\ttorch.Size([1, 256]),\n",
      "\ttorch.Size([1, 256])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.EmbeddingBag(100, 256)(nt3).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([256]),\n",
      "\ttorch.Size([256]),\n",
      "\ttorch.Size([256])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.EmbeddingBag(100, 256)(nt4).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\t(\n",
      "\t\ttorch.Size([1, 256])\n",
      "\t),\n",
      "\t(\n",
      "\t\ttorch.Size([1, 256]),\n",
      "\t\ttorch.Size([1, 256])\n",
      "\t)\n",
      "))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight = torch.rand(100, 256)\n",
    "print_eval(\"torch.nn.functional.embedding_bag(nt2, weight).nested_size()\")\n",
    "print_eval(\"torch.nn.functional.embedding_bag(nt3, weight).nested_size()\")\n",
    "print_eval(\"torch.nn.functional.embedding_bag(nt4, weight).nested_size()\")\n",
    "print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt2).nested_size()\")\n",
    "print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt3).nested_size()\")\n",
    "print_eval(\"torch.nn.EmbeddingBag(100, 256)(nt4).nested_size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt3:\u001b[0m             \n",
      "nested_tensor([\n",
      "\ttensor([3., 6., 7., 2., 0., 6., 0., 3., 9., 2., 4., 4., 5., 0., 0., 6., 3., 7.,\n",
      "\t        7., 4., 7., 5., 9., 7., 5., 7., 6., 1., 7., 7.]),\n",
      "\ttensor([4., 0., 3., 0., 7., 9., 3., 4., 8., 4., 7., 6., 6., 3., 7., 5., 3., 0.,\n",
      "\t        1., 3., 4., 4., 6., 3., 9., 7., 6., 9., 5., 4., 6., 3., 6., 1., 3., 7.,\n",
      "\t        4., 4., 2., 2.]),\n",
      "\ttensor([4., 2., 9., 3., 4., 3., 1., 2., 0., 2., 1., 4., 3., 1., 5., 2., 8., 6.,\n",
      "\t        7., 3., 8., 3., 2., 0., 9., 0., 7., 4., 9., 2., 7., 6., 3., 3., 6., 4.,\n",
      "\t        2., 4., 3., 2., 0., 0., 0., 4., 9., 4., 7., 7., 6., 0.])\n",
      "])\n",
      "\n",
      "\u001b[1;31m$ nt3.size():\u001b[0m      \n",
      "(3, None)\n",
      "\n",
      "\u001b[1;31m$ nt3.nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([30]),\n",
      "\ttorch.Size([40]),\n",
      "\ttorch.Size([50])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nested_tensor(nt3.nested_size(1)):\u001b[0m\n",
      "nested_tensor([\n",
      "\ttensor(30),\n",
      "\ttensor(40),\n",
      "\ttensor(50)\n",
      "])\n",
      "\n",
      "\u001b[1;31m$ nt4:\u001b[0m             \n",
      "nested_tensor([\n",
      "\ttensor([0.1000, 0.2000, 0.2333, 0.0667, 0.0000, 0.2000, 0.0000, 0.1000, 0.3000,\n",
      "\t        0.0667, 0.1333, 0.1333, 0.1667, 0.0000, 0.0000, 0.2000, 0.1000, 0.2333,\n",
      "\t        0.2333, 0.1333, 0.2333, 0.1667, 0.3000, 0.2333, 0.1667, 0.2333, 0.2000,\n",
      "\t        0.0333, 0.2333, 0.2333]),\n",
      "\ttensor([0.1000, 0.0000, 0.0750, 0.0000, 0.1750, 0.2250, 0.0750, 0.1000, 0.2000,\n",
      "\t        0.1000, 0.1750, 0.1500, 0.1500, 0.0750, 0.1750, 0.1250, 0.0750, 0.0000,\n",
      "\t        0.0250, 0.0750, 0.1000, 0.1000, 0.1500, 0.0750, 0.2250, 0.1750, 0.1500,\n",
      "\t        0.2250, 0.1250, 0.1000, 0.1500, 0.0750, 0.1500, 0.0250, 0.0750, 0.1750,\n",
      "\t        0.1000, 0.1000, 0.0500, 0.0500]),\n",
      "\ttensor([0.0800, 0.0400, 0.1800, 0.0600, 0.0800, 0.0600, 0.0200, 0.0400, 0.0000,\n",
      "\t        0.0400, 0.0200, 0.0800, 0.0600, 0.0200, 0.1000, 0.0400, 0.1600, 0.1200,\n",
      "\t        0.1400, 0.0600, 0.1600, 0.0600, 0.0400, 0.0000, 0.1800, 0.0000, 0.1400,\n",
      "\t        0.0800, 0.1800, 0.0400, 0.1400, 0.1200, 0.0600, 0.0600, 0.1200, 0.0800,\n",
      "\t        0.0400, 0.0800, 0.0600, 0.0400, 0.0000, 0.0000, 0.0000, 0.0800, 0.1800,\n",
      "\t        0.0800, 0.1400, 0.1400, 0.1200, 0.0000])\n",
      "])\n",
      "\n",
      "\u001b[1;31m$ nt4.size():\u001b[0m      \n",
      "(3, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt3 = nt3.float()\n",
    "print_eval(\"nt3\")\n",
    "print_eval(\"nt3.size()\")\n",
    "print_eval(\"nt3.nested_size()\")\n",
    "print_eval(\"torch.nested_tensor(nt3.nested_size(1))\")\n",
    "nt4 = nt3 / torch.nested_tensor(nt3.nested_size(1))\n",
    "print_eval(\"nt4\")\n",
    "print_eval(\"nt4.size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt5.nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([30, 10]),\n",
      "\ttorch.Size([40, 10]),\n",
      "\ttorch.Size([50, 10])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.mm(nt5, torch.rand(10, 5)).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([30, 5]),\n",
      "\ttorch.Size([40, 5]),\n",
      "\ttorch.Size([50, 5])\n",
      "))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt5 = torch.nested_tensor([\n",
    "    torch.rand(30, 10),\n",
    "    torch.rand(40, 10),\n",
    "    torch.rand(50, 10)\n",
    "])\n",
    "print_eval(\"nt5.nested_size()\")\n",
    "print_eval(\"torch.mm(nt5, torch.rand(10, 5)).nested_size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt5.argmax(1):\u001b[0m   \n",
      "nested_tensor([\n",
      "\ttensor([19,  5,  1, 17, 27,  3, 27, 26, 24, 28]),\n",
      "\ttensor([ 8, 27, 23, 25, 24, 24,  6, 38,  8,  3]),\n",
      "\ttensor([32, 36,  9,  0, 29, 42, 46, 20, 46, 22])\n",
      "])\n",
      "\n",
      "\u001b[1;31m$ nt5.argmax(1).size():\u001b[0m\n",
      "(3, 10)\n",
      "\n",
      "\u001b[1;31m$ nt5.argmax(1).to_tensor():\u001b[0m\n",
      "tensor([[19,  5,  1, 17, 27,  3, 27, 26, 24, 28],\n",
      "        [ 8, 27, 23, 25, 24, 24,  6, 38,  8,  3],\n",
      "        [32, 36,  9,  0, 29, 42, 46, 20, 46, 22]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval(\"nt5.argmax(1)\")\n",
    "print_eval(\"nt5.argmax(1).size()\")\n",
    "print_eval(\"nt5.argmax(1).to_tensor()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt5.nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([30, 10]),\n",
      "\ttorch.Size([40, 10]),\n",
      "\ttorch.Size([50, 10])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ nt5.argmax(2).nested_size():\u001b[0m\n",
      "torch.NestedSize((\n",
      "\ttorch.Size([30]),\n",
      "\ttorch.Size([40]),\n",
      "\ttorch.Size([50])\n",
      "))\n",
      "\n",
      "\u001b[1;31m$ torch.nn.functional.cross_entropy(nt5, nt5.argmax(2)):\u001b[0m\n",
      "nested_tensor([\n",
      "\ttensor(1.9369),\n",
      "\ttensor(1.9437),\n",
      "\ttensor(1.9298)\n",
      "])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_eval(\"nt5.nested_size()\")\n",
    "print_eval(\"nt5.argmax(2).nested_size()\")\n",
    "print_eval(\"torch.nn.functional.cross_entropy(nt5, nt5.argmax(2))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt6.lu()[0].size():\u001b[0m\n",
      "(3, None, None)\n",
      "\n",
      "\u001b[1;31m$ nt6.lu()[1].size():\u001b[0m\n",
      "(3, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt6 = torch.nested_tensor([torch.rand(10, 10), torch.rand(20, 20), torch.rand(30, 30)])\n",
    "print_eval(\"nt6.lu()[0].size()\")\n",
    "print_eval(\"nt6.lu()[1].size()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ torch.mm(nt7, nt8):\u001b[0m\n",
      "nested_tensor([\n",
      "\t[\n",
      "\t\ttensor([[2.4037]]),\n",
      "\t\ttensor([[3.6637, 4.1156],\n",
      "\t\t        [4.9553, 4.3066]])\n",
      "\t],\n",
      "\t[\n",
      "\t\ttensor([[7.2216, 7.7442, 8.4139],\n",
      "\t\t        [8.2279, 7.1767, 8.8830],\n",
      "\t\t        [7.3217, 7.0047, 7.2424]])\n",
      "\t]\n",
      "])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nt7 = torch.nested_tensor([[torch.rand(1, 10), torch.rand(2, 20)], [torch.rand(3, 30)]])\n",
    "nt8 = torch.nested_tensor([[torch.rand(10, 1), torch.rand(20, 2)], [torch.rand(30, 3)]])\n",
    "print_eval(\"torch.mm(nt7, nt8)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
