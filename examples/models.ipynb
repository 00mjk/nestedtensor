{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dispatch setup must only be executed once. The monkey patching determines whether it is overwriting already\n",
    "# set attributes to make sure it is not overwriting critical code. This will change in the near future\n",
    "# with PyTorch's improved extension support being added (akin to numpy).\n",
    "from nestedtensor import torch\n",
    "import time as time_module\n",
    "def print_eval(s):\n",
    "    print((\"\\033[1;31m$ \" + s + \":\\033[0m\").ljust(30) + \"\\n{}\\n\".format(str(eval(s))))\n",
    "def time(fn):\n",
    "    t0 = time_module.time()\n",
    "    count = 0\n",
    "    past = 0\n",
    "    while past < 10.0:\n",
    "        fn()\n",
    "        past = time_module.time() - t0\n",
    "        count += 1\n",
    "    past = past / count\n",
    "    return \"average {:2.4f}ms based on {} samples\".format(past * 1000, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ time(lambda: model(text, offsets)):\u001b[0m\n",
      "average 0.2323ms based on 43047 samples\n",
      "\n",
      "\u001b[1;31m$ time(lambda: model(nt_text, None)):\u001b[0m\n",
      "average 0.3689ms based on 27109 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_tensors(num_tensor, vocab_size):\n",
    "    sentence_lengths = torch.normal(75.0, 10.0, size=(num_tensor,)).long()\n",
    "    return [(torch.rand(l) * vocab_size).long() for l in sentence_lengths]\n",
    "\n",
    "def generate_text(text):\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text.to(torch.int64), offsets\n",
    "\n",
    "class TextSentiment(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        emb = self.embedding(text, offsets)\n",
    "        return self.fc(emb)\n",
    "    \n",
    "vocab_size = 10000\n",
    "model = TextSentiment(10000, 256, 5)\n",
    "tensors = generate_tensors(16, 10000)\n",
    "text, offsets = generate_text(tensors)\n",
    "nt_text = torch.nested_tensor(tensors)\n",
    "\n",
    "print_eval(\"time(lambda: model(text, offsets))\")\n",
    "print_eval(\"time(lambda: model(nt_text, None))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ images.numel():\u001b[0m  \n",
      "768000\n",
      "\n",
      "\u001b[1;31m$ time(lambda: model(images)):\u001b[0m\n",
      "average 47.6147ms based on 211 samples\n",
      "\n",
      "\u001b[1;31m$ time(lambda: model(nested_images)):\u001b[0m\n",
      "average 113.2366ms based on 89 samples\n",
      "\n",
      "\u001b[1;31m$ nested_irregular_images.numel():\u001b[0m\n",
      "692112\n",
      "\n",
      "\u001b[1;31m$ nested_irregular_images.size():\u001b[0m\n",
      "(64, 3, None, None)\n",
      "\n",
      "\u001b[1;31m$ time(lambda: model(nested_irregular_images)):\u001b[0m\n",
      "average 1435.1884ms based on 7 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "images = torch.rand(128, 3, 40, 50)\n",
    "print_eval(\"images.numel()\")\n",
    "print_eval(\"time(lambda: model(images))\")\n",
    "\n",
    "nested_images = torch.nested_tensor(torch.rand(128, 3, 40, 50).unbind())\n",
    "print_eval(\"time(lambda: model(nested_images))\")\n",
    "\n",
    "# There is still about a 10x gap in performance, which however\n",
    "# can be significantly allieviated via custom code (e.g. using im2col).\n",
    "images = [torch.rand(3, (i * 16) % 40 + 40, (i * 16) % 50 + 40) for i in range(64)]\n",
    "nested_irregular_images = torch.nested_tensor(images)\n",
    "print_eval(\"nested_irregular_images.numel()\")\n",
    "print_eval(\"nested_irregular_images.size()\")\n",
    "print_eval(\"time(lambda: model(nested_irregular_images))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m$ nt_text.nested_size(1):\u001b[0m\n",
      "(80, 71, 63, 65, 77, 85, 59, 62, 65, 80, 78, 85, 77, 78, 64, 80, 82, 72, 67, 90, 70, 67, 63, 70, 68, 79, 74, 86, 76, 69, 50, 70)\n",
      "\n",
      "\u001b[1;31m$ nt_text.numel():\u001b[0m \n",
      "594432\n",
      "\n",
      "\u001b[1;31m$ text.numel():\u001b[0m    \n",
      "614400\n",
      "\n",
      "\u001b[1;31m$ time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(nt_text, (h0, c0))):\u001b[0m\n",
      "average 1812.3047ms based on 6 samples\n",
      "\n",
      "\u001b[1;31m$ time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(text, (h0, c0))):\u001b[0m\n",
      "average 372.5485ms based on 28 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_tensors(num_tensor, num_features):\n",
    "    sentence_lengths = torch.normal(75.0, 10.0, size=(num_tensor,)).long()\n",
    "    return [torch.rand(l.item(), num_features) for l in sentence_lengths]\n",
    "\n",
    "tensors = generate_tensors(32, 256)\n",
    "nt_text = torch.nested_tensor(tensors)\n",
    "text = torch.rand(32, 75, 256)\n",
    "\n",
    "h0 = torch.randn(6, len(nt_text), 512)\n",
    "c0 = torch.randn(6, len(nt_text), 512)\n",
    "print_eval(\"nt_text.nested_size(1)\")\n",
    "print_eval(\"nt_text.numel()\")\n",
    "print_eval(\"text.numel()\")\n",
    "print_eval(\"time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(nt_text, (h0, c0)))\")\n",
    "print_eval(\"time(lambda: torch.nn.LSTM(256, 512, 6, batch_first=True)(text, (h0, c0)))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
